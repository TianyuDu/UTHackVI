{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import datetime\n",
    "from sklearn.model_selection import train_test_split\n",
    "import _pickle as pickle\n",
    "from typing import List\n",
    "import os\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chakin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>author</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1956967341</td>\n",
       "      <td>empty</td>\n",
       "      <td>xoshayzers</td>\n",
       "      <td>@tiffanylue i know  i was listenin to bad habi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1956967666</td>\n",
       "      <td>sadness</td>\n",
       "      <td>wannamama</td>\n",
       "      <td>Layin n bed with a headache  ughhhh...waitin o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1956967696</td>\n",
       "      <td>sadness</td>\n",
       "      <td>coolfunky</td>\n",
       "      <td>Funeral ceremony...gloomy friday...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1956967789</td>\n",
       "      <td>enthusiasm</td>\n",
       "      <td>czareaquino</td>\n",
       "      <td>wants to hang out with friends SOON!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1956968416</td>\n",
       "      <td>neutral</td>\n",
       "      <td>xkilljoyx</td>\n",
       "      <td>@dannycastillo We want to trade with someone w...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     tweet_id   sentiment       author  \\\n",
       "0  1956967341       empty   xoshayzers   \n",
       "1  1956967666     sadness    wannamama   \n",
       "2  1956967696     sadness    coolfunky   \n",
       "3  1956967789  enthusiasm  czareaquino   \n",
       "4  1956968416     neutral    xkilljoyx   \n",
       "\n",
       "                                             content  \n",
       "0  @tiffanylue i know  i was listenin to bad habi...  \n",
       "1  Layin n bed with a headache  ughhhh...waitin o...  \n",
       "2                Funeral ceremony...gloomy friday...  \n",
       "3               wants to hang out with friends SOON!  \n",
       "4  @dannycastillo We want to trade with someone w...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"./text_emotion.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   Name  Dimension                     Corpus VocabularySize  \\\n",
      "2          fastText(en)        300                  Wikipedia           2.5M   \n",
      "11         GloVe.6B.50d         50  Wikipedia+Gigaword 5 (6B)           400K   \n",
      "12        GloVe.6B.100d        100  Wikipedia+Gigaword 5 (6B)           400K   \n",
      "13        GloVe.6B.200d        200  Wikipedia+Gigaword 5 (6B)           400K   \n",
      "14        GloVe.6B.300d        300  Wikipedia+Gigaword 5 (6B)           400K   \n",
      "15       GloVe.42B.300d        300          Common Crawl(42B)           1.9M   \n",
      "16      GloVe.840B.300d        300         Common Crawl(840B)           2.2M   \n",
      "17    GloVe.Twitter.25d         25               Twitter(27B)           1.2M   \n",
      "18    GloVe.Twitter.50d         50               Twitter(27B)           1.2M   \n",
      "19   GloVe.Twitter.100d        100               Twitter(27B)           1.2M   \n",
      "20   GloVe.Twitter.200d        200               Twitter(27B)           1.2M   \n",
      "21  word2vec.GoogleNews        300          Google News(100B)           3.0M   \n",
      "\n",
      "      Method Language    Author  \n",
      "2   fastText  English  Facebook  \n",
      "11     GloVe  English  Stanford  \n",
      "12     GloVe  English  Stanford  \n",
      "13     GloVe  English  Stanford  \n",
      "14     GloVe  English  Stanford  \n",
      "15     GloVe  English  Stanford  \n",
      "16     GloVe  English  Stanford  \n",
      "17     GloVe  English  Stanford  \n",
      "18     GloVe  English  Stanford  \n",
      "19     GloVe  English  Stanford  \n",
      "20     GloVe  English  Stanford  \n",
      "21  word2vec  English    Google  \n"
     ]
    }
   ],
   "source": [
    "chakin.search(lang=\"English\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHAKIN_INDEX = 16\n",
    "# NUMBER_OF_DIMENSIONS = 300\n",
    "# SUBFOLDER_NAME = \"GloVe.840B.300d\"\n",
    "CHAKIN_INDEX = 18\n",
    "NUMBER_OF_DIMENSIONS = 50\n",
    "SUBFOLDER_NAME = \"GloVe.Twitter.50d\"\n",
    "\n",
    "DATA_FOLDER = \"embeddings\"\n",
    "ZIP_FILE = os.path.join(DATA_FOLDER, \"{}.zip\".format(SUBFOLDER_NAME))\n",
    "ZIP_FILE_ALT = \"glove\" + ZIP_FILE[5:]  # sometimes it's lowercase only...\n",
    "UNZIP_FOLDER = os.path.join(DATA_FOLDER, SUBFOLDER_NAME)\n",
    "if SUBFOLDER_NAME[-1] == \"d\":\n",
    "    GLOVE_FILENAME = os.path.join(UNZIP_FOLDER, \"{}.txt\".format(SUBFOLDER_NAME))\n",
    "else:\n",
    "    GLOVE_FILENAME = os.path.join(UNZIP_FOLDER, \"{}.{}d.txt\".format(SUBFOLDER_NAME, NUMBER_OF_DIMENSIONS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'embeddings'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading embeddings to 'embeddings/GloVe.Twitter.50d.zip'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test: 100% ||                                      | Time:  0:03:45   6.4 MiB/s\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'embeddings/GloVe.Twitter.50d.zip'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-59926beff6bf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mZIP_FILE\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mZIP_FILE_ALT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mZIP_FILE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mZIP_FILE_ALT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mzipfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mZIP_FILE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"r\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mzip_ref\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Extracting embeddings to '{}'\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mUNZIP_FOLDER\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mzip_ref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextractall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mUNZIP_FOLDER\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/zipfile.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, file, mode, compression, allowZip64)\u001b[0m\n\u001b[1;32m   1088\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1089\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1090\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilemode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1091\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1092\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mfilemode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodeDict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'embeddings/GloVe.Twitter.50d.zip'"
     ]
    }
   ],
   "source": [
    "# if not os.path.exists(ZIP_FILE) and not os.path.exists(UNZIP_FOLDER):\n",
    "#     # GloVe by Stanford is licensed Apache 2.0: \n",
    "#     #     https://github.com/stanfordnlp/GloVe/blob/master/LICENSE\n",
    "#     #     http://nlp.stanford.edu/data/glove.twitter.27B.zip\n",
    "#     #     Copyright 2014 The Board of Trustees of The Leland Stanford Junior University\n",
    "#     print(\"Downloading embeddings to '{}'\".format(ZIP_FILE))\n",
    "#     chakin.download(number=CHAKIN_INDEX, save_dir='./{}'.format(DATA_FOLDER))\n",
    "# else:\n",
    "#     print(\"Embeddings already downloaded.\")\n",
    "    \n",
    "# if not os.path.exists(UNZIP_FOLDER):\n",
    "#     import zipfile\n",
    "#     if not os.path.exists(ZIP_FILE) and os.path.exists(ZIP_FILE_ALT):\n",
    "#         ZIP_FILE = ZIP_FILE_ALT\n",
    "#     with zipfile.ZipFile(ZIP_FILE,\"r\") as zip_ref:\n",
    "#         print(\"Extracting embeddings to '{}'\".format(UNZIP_FOLDER))\n",
    "#         zip_ref.extractall(UNZIP_FOLDER)\n",
    "# else:\n",
    "#     print(\"Embeddings already extracted.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_embedding_from_disks(glove_filename, with_indexes=True):\n",
    "    \"\"\"\n",
    "    Read a GloVe txt file. If `with_indexes=True`, we return a tuple of two dictionnaries\n",
    "    `(word_to_index_dict, index_to_embedding_array)`, otherwise we return only a direct \n",
    "    `word_to_embedding_dict` dictionnary mapping from a string to a numpy array.\n",
    "    \"\"\"\n",
    "    if with_indexes:\n",
    "        word_to_index_dict = dict()\n",
    "        index_to_embedding_array = []\n",
    "    else:\n",
    "        word_to_embedding_dict = dict()\n",
    "\n",
    "    \n",
    "    with open(glove_filename, 'r') as glove_file:\n",
    "        for (i, line) in tqdm(enumerate(glove_file)):\n",
    "\n",
    "            split = line.split(' ')\n",
    "            \n",
    "            word = split[0]\n",
    "            \n",
    "            representation = split[1:]\n",
    "            representation = np.array(\n",
    "                [float(val) for val in representation]\n",
    "            )\n",
    "            \n",
    "            if with_indexes:\n",
    "                word_to_index_dict[word] = i\n",
    "                index_to_embedding_array.append(representation)\n",
    "            else:\n",
    "                word_to_embedding_dict[word] = representation\n",
    "\n",
    "    _WORD_NOT_FOUND = [0.0]* len(representation)  # Empty representation for unknown words.\n",
    "    if with_indexes:\n",
    "        _LAST_INDEX = i + 1\n",
    "        word_to_index_dict = defaultdict(lambda: _LAST_INDEX, word_to_index_dict)\n",
    "        index_to_embedding_array = np.array(index_to_embedding_array + [_WORD_NOT_FOUND])\n",
    "        return word_to_index_dict, index_to_embedding_array\n",
    "    else:\n",
    "        word_to_embedding_dict = defaultdict(lambda: _WORD_NOT_FOUND)\n",
    "        return word_to_embedding_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "GLOVE_FILENAME = \"../data/glove.840B.300d.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1893it [00:00, 9462.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading embedding from disks...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2196017it [04:02, 9045.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding loaded from disks.\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading embedding from disks...\")\n",
    "word_to_index, index_to_embedding = load_embedding_from_disks(GLOVE_FILENAME, with_indexes=True)\n",
    "print(\"Embedding loaded from disks.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab Size: 2196018\n",
      "Embedding Dim: 300\n"
     ]
    }
   ],
   "source": [
    "# Model Parameters\n",
    "# embedding_size = 300\n",
    "\n",
    "vocab_size, embedding_dim = index_to_embedding.shape\n",
    "print(f\"Vocab Size: {vocab_size}\\nEmbedding Dim: {embedding_dim}\")\n",
    "\n",
    "# batch_size = 24\n",
    "lstm_units = (512, 1024)\n",
    "num_classes = 13\n",
    "iterations = 20\n",
    "max_seq_length = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "171974"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_to_index[\"unk\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['surprise', 'hate', 'relief', 'fun', 'neutral', 'boredom', 'empty', 'enthusiasm', 'happiness', 'sadness', 'worry', 'anger', 'love']\n"
     ]
    }
   ],
   "source": [
    "SENTI_LST = list(set(df[\"sentiment\"]))\n",
    "print(SENTI_LST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word2int(w: str) -> int:\n",
    "    try:\n",
    "        idx = word_to_index[w]\n",
    "    except KeyError:\n",
    "        idx = word_to_index[\"unk\"]\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_lst, y_lst = [], []\n",
    "for sentence, senti in zip(df[\"content\"], df[\"sentiment\"]):\n",
    "    # ==== Encode x ====\n",
    "    tokens = sentence.lower().split()\n",
    "    word_ints = np.array([word2int(x) for x in tokens])\n",
    "    X_lst.append(word_ints)\n",
    "    \n",
    "    # ==== Encode y ====\n",
    "    label = np.zeros([num_classes])\n",
    "    senti_index = SENTI_LST.index(senti)\n",
    "    label[senti_index] = 1\n",
    "    y_lst.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "zzzz = [len(x) for x in X_lst]\n",
    "plt.hist(zzzz)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_lst = pad_sequences(X_lst, maxlen=max_seq_length, padding=\"post\", truncating=\"post\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40000, 40)\n",
      "(40000, 13)\n"
     ]
    }
   ],
   "source": [
    "X_raw = np.stack(X_lst)\n",
    "y_raw = np.stack(y_lst)\n",
    "print(X_raw.shape)\n",
    "print(y_raw.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['@', 'cayogial', 'i', 'wanted', 'to', 'come', 'to', 'bz', 'this', 'summer', ':/', 'not', 'so', 'sure', 'anymore...', 'a', \"teacher's\", 'life', 'in', 'the', 'summer', 'sucks']\n",
      "[433, 2196017, 108, 652, 4, 248, 4, 121902, 27, 1065, 2196017, 35, 59, 270, 2196017, 6, 2196017, 203, 7, 2, 1065, 5452]\n",
      "[    433 2196017     108     652       4     248       4  121902      27\n",
      "    1065 2196017      35      59     270 2196017       6 2196017     203\n",
      "       7       2    1065    5452       0       0       0       0       0\n",
      "       0       0       0       0       0       0       0       0       0\n",
      "       0       0       0       0]\n"
     ]
    }
   ],
   "source": [
    "s = df[\"content\"][99]\n",
    "s = s.lower().split()\n",
    "p = [word_to_index[x] for x in s]\n",
    "print(s)\n",
    "print(p)\n",
    "print(X_raw[99])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# if bool(input(\"Re-read embedding?[Y/N]>>> \").upper() == \"Y\"):\n",
    "#     with open('/home/ec2-user/data/glove.840B.300d.txt') as f:\n",
    "#         content = f.readlines()\n",
    "#     total_dict = {}\n",
    "#     for i in range(len(content)):\n",
    "#         progbar(i, len(content), 40)\n",
    "#         this = content[i].split()\n",
    "#         try:\n",
    "#             total_dict[this[0]] = np.array(this[1:]).astype(np.float32)\n",
    "#         except:\n",
    "#             for i in range(len(this[1:])):\n",
    "#                 try:\n",
    "#                     np.array(this[1:][i]).astype(np.float32)\n",
    "#                 except:\n",
    "#                     this[i+1] = '0.0'\n",
    "#             total_dict[this[0]] = np.array(this[1:]).astype(np.float32)\n",
    "\n",
    "#     with open('../data/dict.pkl', 'wb') as f:\n",
    "#         pickle.dump(total_dict, f)\n",
    "# else:\n",
    "#     with open('../data/dict.pkl', 'rb') as f:\n",
    "#         total_dict = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def s5_idx(emo) -> int:\n",
    "#     if emo in [\"happiness\", \"enthusiasm\", \"love\", \"relief\", \"fun\"]:\n",
    "#         return 0\n",
    "#     elif emo in [\"anger\", \"hate\"]:\n",
    "#         return 1\n",
    "#     elif emo in [\"sadness\", \"empty\", \"boredom\", \"worry\"]:\n",
    "#         return 2\n",
    "#     elif emo in [\"neutral\"]:\n",
    "#         return 3\n",
    "#     elif emo in [\"surprise\"]:\n",
    "#         return 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# senti5 = [\"happy\", \"aggresive\", \"boring\", \"neutral\", \"surprise\"]\n",
    "# senti_lst = list(set(df[\"sentiment\"]))\n",
    "# print(senti_lst)\n",
    "# print(senti5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def word2vec(sentence: List[str], max_seq_length=20) -> np.ndarray:\n",
    "#     sentence = item.split()\n",
    "#     vec_lst = list()\n",
    "#     for word in sentence:\n",
    "#         if len(vec_lst) < max_seq_length and word[0] != \"@\":\n",
    "#             try:\n",
    "#                 vec_lst.append(total_dict[word][:num_dimensions])\n",
    "#             except KeyError:\n",
    "#     #             vec_lst.append(np.zeros([num_dimensions]))\n",
    "#                 vec_lst.append(total_dict[\"something\"])\n",
    "#     while len(vec_lst) < max_seq_length:\n",
    "#         vec_lst.append(np.zeros([num_dimensions])\n",
    "#         )\n",
    "#     vec_ary = np.stack(vec_lst)\n",
    "#     return vec_ary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# X_raw = []\n",
    "# y_raw = []\n",
    "# for i, (senti, item) in enumerate(zip(df[\"sentiment\"], df[\"content\"])):\n",
    "#     progbar(i+1, len(df), 50)\n",
    "#     X_raw.append(word2vec(item))\n",
    "    \n",
    "#     # ==== Process y ====\n",
    "#     y_idx = s5_idx(senti)\n",
    "#     label = np.zeros([5])\n",
    "#     label[y_idx] = 1\n",
    "#     assert sum(label) == 1\n",
    "#     y_raw.append(label)\n",
    "# X_raw = np.array(X_raw)\n",
    "# y_raw = np.array(y_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(f\"X shape: {X_raw.shape}\")\n",
    "# print(f\"y shape: {y_raw.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (i, truth) in zip(range(y_raw.shape[0]), df[\"sentiment\"]):\n",
    "    idx = np.squeeze(np.where(y_raw[i, :] == 1))\n",
    "    assert SENTI_LST[idx] == truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, X_test,\n",
    " y_train, y_test) = train_test_split(\n",
    "    X_raw, y_raw,\n",
    "    test_size=0.2,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "(X_train, X_val,\n",
    " y_train, y_val) = train_test_split(\n",
    "    X_train, y_train,\n",
    "    test_size=0.2,\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training and testing set generated,\n",
      "X_train shape: (25600, 40)\n",
      "y_train shape: (25600, 13)\n",
      "X_test shape: (8000, 40)\n",
      "y_test shape: (8000, 13)\n",
      "X_validation shape: (6400, 40)\n",
      "y_validation shape: (6400, 13)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Training and testing set generated,\\\n",
    "\\nX_train shape: {X_train.shape}\\\n",
    "\\ny_train shape: {y_train.shape}\\\n",
    "\\nX_test shape: {X_test.shape}\\\n",
    "\\ny_test shape: {y_test.shape}\\\n",
    "\\nX_validation shape: {X_val.shape}\\\n",
    "\\ny_validation shape: {y_val.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_batches = X_train.reshape(25, 1024, max_seq_length)\n",
    "y_train_batches = y_train.reshape(25, 1024, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2196018, 300)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_to_embedding.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = None\n",
    "tf.reset_default_graph()\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "with tf.name_scope(\"DATA_IO\"):\n",
    "    word_ids = tf.placeholder(\n",
    "        tf.int32,\n",
    "        shape=[None, max_seq_length]\n",
    "    )\n",
    "    \n",
    "    y = tf.placeholder(\n",
    "        tf.float32,\n",
    "        shape=[None, num_classes]\n",
    "    )\n",
    "\n",
    "with tf.name_scope(\"EMBED\"):\n",
    "    embedding = tf.Variable(\n",
    "        tf.constant(0.0, shape=index_to_embedding.shape),\n",
    "        trainable=False,\n",
    "        name=\"EMBEDDING\"\n",
    "    )\n",
    "    \n",
    "    word_representation_layer = tf.nn.embedding_lookup(\n",
    "        params=embedding,\n",
    "        ids=word_ids\n",
    "    )\n",
    "    \n",
    "    embedding_placeholder = tf.placeholder(\n",
    "        tf.float32,\n",
    "        shape=index_to_embedding.shape\n",
    "    )\n",
    "    \n",
    "    embedding_init = embedding.assign(embedding_placeholder)\n",
    "    \n",
    "    _ = sess.run(\n",
    "        embedding_init, \n",
    "            feed_dict={\n",
    "                embedding_placeholder: index_to_embedding\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_of_words = [\"Hello\", \"World\", \"!\"]\n",
    "batch_indexes = [word_to_index[w.lower()] for w in batch_of_words]\n",
    "batch_indexes = pad_sequences([batch_indexes], maxlen=max_seq_length, padding=\"post\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 40, 300)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = sess.run(word_representation_layer, feed_dict={word_ids: batch_indexes})\n",
    "m.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"RNN\"):\n",
    "    cell = tf.nn.rnn_cell.MultiRNNCell(\n",
    "        [tf.nn.rnn_cell.LSTMCell(\n",
    "            num_units=units,\n",
    "            name=f\"LSTM_LAYER_{i}\")\n",
    "            for i, units in enumerate(lstm_units)\n",
    "         ])\n",
    "    \n",
    "    lstm_cell = tf.contrib.rnn.DropoutWrapper(\n",
    "        cell=cell,\n",
    "        output_keep_prob=0.75\n",
    "    )\n",
    "    outputs, state = tf.nn.dynamic_rnn(\n",
    "        lstm_cell, \n",
    "        word_representation_layer,\n",
    "        dtype=tf.float32\n",
    "    )\n",
    "\n",
    "with tf.name_scope(\"OUTPUT\"):\n",
    "    weight = tf.Variable(\n",
    "        tf.truncated_normal(\n",
    "            [lstm_units[-1], num_classes]\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    bias = tf.Variable(\n",
    "        tf.random_normal(shape=[num_classes])\n",
    "    )\n",
    "\n",
    "# Option i)\n",
    "#     value = tf.transpose(value, [1, 0, 2])\n",
    "#     last = tf.gather(value, int(value.get_shape()[0]) - 1)\n",
    "# Option ii)\n",
    "    last = outputs[:, -1, :]\n",
    "    pred = tf.matmul(last, weight) + bias\n",
    "    pred_idx = tf.argmax(pred, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Accuracy:0' shape=() dtype=string>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with tf.name_scope(\"METRICS\"):\n",
    "    correct_pred = tf.equal(\n",
    "        tf.argmax(pred, axis=1),\n",
    "        tf.argmax(y, axis=1)\n",
    "    )\n",
    "\n",
    "    accuracy = tf.reduce_mean(\n",
    "        tf.cast(correct_pred, tf.float32)\n",
    "    )\n",
    "\n",
    "with tf.name_scope(\"LOSSES\"):\n",
    "    loss = tf.reduce_mean(\n",
    "        tf.nn.softmax_cross_entropy_with_logits_v2(\n",
    "            logits=pred,\n",
    "            labels=y\n",
    "        )\n",
    "    )\n",
    "    optimizer = tf.train.AdamOptimizer().minimize(loss)\n",
    "\n",
    "tf.summary.scalar(\"Loss\", loss)\n",
    "tf.summary.scalar(\"Accuracy\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs[0]: train batch avg accuracy=0.21363280713558197, val accuracy=0.21296875178813934\n",
      "Epochs[1]: train batch avg accuracy=0.208984375, val accuracy=0.21437500417232513\n",
      "Epochs[2]: train batch avg accuracy=0.21281249821186066, val accuracy=0.20781250298023224\n",
      "Epochs[3]: train batch avg accuracy=0.2126171886920929, val accuracy=0.21031250059604645\n",
      "Epochs[4]: train batch avg accuracy=0.21167968213558197, val accuracy=0.21812500059604645\n",
      "Epochs[5]: train batch avg accuracy=0.21691405773162842, val accuracy=0.2071875035762787\n",
      "Epochs[6]: train batch avg accuracy=0.21617187559604645, val accuracy=0.21406249701976776\n",
      "Epochs[7]: train batch avg accuracy=0.21703125536441803, val accuracy=0.21156249940395355\n",
      "Epochs[8]: train batch avg accuracy=0.21507813036441803, val accuracy=0.2162500023841858\n",
      "Epochs[9]: train batch avg accuracy=0.21476562321186066, val accuracy=0.2134374976158142\n",
      "Epochs[10]: train batch avg accuracy=0.21335937082767487, val accuracy=0.2162500023841858\n",
      "Epochs[11]: train batch avg accuracy=0.21824218332767487, val accuracy=0.21328124403953552\n",
      "Epochs[12]: train batch avg accuracy=0.21613281965255737, val accuracy=0.20374999940395355\n",
      "Epochs[13]: train batch avg accuracy=0.21449218690395355, val accuracy=0.2162500023841858\n",
      "Epochs[14]: train batch avg accuracy=0.21308593451976776, val accuracy=0.21125000715255737\n",
      "Epochs[15]: train batch avg accuracy=0.21410156786441803, val accuracy=0.21375000476837158\n",
      "Epochs[16]: train batch avg accuracy=0.21437500417232513, val accuracy=0.21203124523162842\n",
      "Epochs[17]: train batch avg accuracy=0.2155468761920929, val accuracy=0.21171875298023224\n",
      "Epochs[18]: train batch avg accuracy=0.2160937488079071, val accuracy=0.2173437476158142\n",
      "Epochs[19]: train batch avg accuracy=0.21910156309604645, val accuracy=0.2121874988079071\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[40,25600,1024] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node RNN/rnn/TensorArrayStack/TensorArrayGatherV3 (defined at <ipython-input-71-0aa4ba97aeae>:16)  = TensorArrayGatherV3[_class=[\"loc:@RNN/rnn/TensorArray\"], dtype=DT_FLOAT, element_shape=[?,1024], _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](RNN/rnn/TensorArray, RNN/rnn/TensorArrayStack/range, RNN/rnn/while/Exit_2)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[{{node OUTPUT/ArgMax/_83}} = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_311_OUTPUT/ArgMax\", tensor_type=DT_INT64, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\nCaused by op 'RNN/rnn/TensorArrayStack/TensorArrayGatherV3', defined at:\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 127, in start\n    self.asyncio_loop.run_forever()\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/asyncio/base_events.py\", line 422, in run_forever\n    self._run_once()\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/asyncio/base_events.py\", line 1432, in _run_once\n    handle._run()\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/asyncio/events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 117, in _handle_events\n    handler_func(fileobj, events)\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2662, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2785, in _run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2903, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2963, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-71-0aa4ba97aeae>\", line 16, in <module>\n    dtype=tf.float32\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/ops/rnn.py\", line 664, in dynamic_rnn\n    dtype=dtype)\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/ops/rnn.py\", line 876, in _dynamic_rnn_loop\n    final_outputs = tuple(ta.stack() for ta in output_final_ta)\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/ops/rnn.py\", line 876, in <genexpr>\n    final_outputs = tuple(ta.stack() for ta in output_final_ta)\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/ops/tensor_array_ops.py\", line 856, in stack\n    return self._implementation.stack(name=name)\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/ops/tensor_array_ops.py\", line 289, in stack\n    return self.gather(math_ops.range(0, self.size()), name=name)\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/ops/tensor_array_ops.py\", line 303, in gather\n    element_shape=element_shape)\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/ops/gen_data_flow_ops.py\", line 6031, in tensor_array_gather_v3\n    flow_in=flow_in, dtype=dtype, element_shape=element_shape, name=name)\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 488, in new_func\n    return func(*args, **kwargs)\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3274, in create_op\n    op_def=op_def)\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1770, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[40,25600,1024] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node RNN/rnn/TensorArrayStack/TensorArrayGatherV3 (defined at <ipython-input-71-0aa4ba97aeae>:16)  = TensorArrayGatherV3[_class=[\"loc:@RNN/rnn/TensorArray\"], dtype=DT_FLOAT, element_shape=[?,1024], _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](RNN/rnn/TensorArray, RNN/rnn/TensorArrayStack/range, RNN/rnn/while/Exit_2)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[{{node OUTPUT/ArgMax/_83}} = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_311_OUTPUT/ArgMax\", tensor_type=DT_INT64, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1319\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[40,25600,1024] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node RNN/rnn/TensorArrayStack/TensorArrayGatherV3}} = TensorArrayGatherV3[_class=[\"loc:@RNN/rnn/TensorArray\"], dtype=DT_FLOAT, element_shape=[?,1024], _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](RNN/rnn/TensorArray, RNN/rnn/TensorArrayStack/range, RNN/rnn/while/Exit_2)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[{{node OUTPUT/ArgMax/_83}} = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_311_OUTPUT/ArgMax\", tensor_type=DT_INT64, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-74-025f7ea859d2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpred_idx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mword_ids\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m \u001b[0mtrain_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0mtest_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0mval_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-74-025f7ea859d2>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(src)\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_summary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpred_idx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mword_ids\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0mtrain_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0mtest_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36meval\u001b[0;34m(self, feed_dict, session)\u001b[0m\n\u001b[1;32m    711\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    712\u001b[0m     \"\"\"\n\u001b[0;32m--> 713\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_eval_using_default_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    715\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_eval_using_default_session\u001b[0;34m(tensors, feed_dict, graph, session)\u001b[0m\n\u001b[1;32m   5155\u001b[0m                        \u001b[0;34m\"the tensor's graph is different from the session's \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5156\u001b[0m                        \"graph.\")\n\u001b[0;32m-> 5157\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1346\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1347\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merror_interpolation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1348\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1350\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[40,25600,1024] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node RNN/rnn/TensorArrayStack/TensorArrayGatherV3 (defined at <ipython-input-71-0aa4ba97aeae>:16)  = TensorArrayGatherV3[_class=[\"loc:@RNN/rnn/TensorArray\"], dtype=DT_FLOAT, element_shape=[?,1024], _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](RNN/rnn/TensorArray, RNN/rnn/TensorArrayStack/range, RNN/rnn/while/Exit_2)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[{{node OUTPUT/ArgMax/_83}} = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_311_OUTPUT/ArgMax\", tensor_type=DT_INT64, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\nCaused by op 'RNN/rnn/TensorArrayStack/TensorArrayGatherV3', defined at:\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 127, in start\n    self.asyncio_loop.run_forever()\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/asyncio/base_events.py\", line 422, in run_forever\n    self._run_once()\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/asyncio/base_events.py\", line 1432, in _run_once\n    handle._run()\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/asyncio/events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 117, in _handle_events\n    handler_func(fileobj, events)\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2662, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2785, in _run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2903, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2963, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-71-0aa4ba97aeae>\", line 16, in <module>\n    dtype=tf.float32\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/ops/rnn.py\", line 664, in dynamic_rnn\n    dtype=dtype)\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/ops/rnn.py\", line 876, in _dynamic_rnn_loop\n    final_outputs = tuple(ta.stack() for ta in output_final_ta)\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/ops/rnn.py\", line 876, in <genexpr>\n    final_outputs = tuple(ta.stack() for ta in output_final_ta)\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/ops/tensor_array_ops.py\", line 856, in stack\n    return self._implementation.stack(name=name)\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/ops/tensor_array_ops.py\", line 289, in stack\n    return self.gather(math_ops.range(0, self.size()), name=name)\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/ops/tensor_array_ops.py\", line 303, in gather\n    element_shape=element_shape)\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/ops/gen_data_flow_ops.py\", line 6031, in tensor_array_gather_v3\n    flow_in=flow_in, dtype=dtype, element_shape=element_shape, name=name)\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 488, in new_func\n    return func(*args, **kwargs)\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3274, in create_op\n    op_def=op_def)\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1770, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[40,25600,1024] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node RNN/rnn/TensorArrayStack/TensorArrayGatherV3 (defined at <ipython-input-71-0aa4ba97aeae>:16)  = TensorArrayGatherV3[_class=[\"loc:@RNN/rnn/TensorArray\"], dtype=DT_FLOAT, element_shape=[?,1024], _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](RNN/rnn/TensorArray, RNN/rnn/TensorArrayStack/range, RNN/rnn/while/Exit_2)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[{{node OUTPUT/ArgMax/_83}} = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_311_OUTPUT/ArgMax\", tensor_type=DT_INT64, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n"
     ]
    }
   ],
   "source": [
    "saver = tf.train.Saver()\n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "merged = tf.summary.merge_all()\n",
    "logdir = \"./tensorboard/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\") + \"/\"\n",
    "writer = tf.summary.FileWriter(logdir, sess.graph)\n",
    "\n",
    "for e in range(iterations):\n",
    "    for X_batch, y_batch in zip(X_train_batches, y_train_batches):\n",
    "        sess.run(\n",
    "            optimizer,\n",
    "            feed_dict={\n",
    "                word_ids: X_batch,\n",
    "                y: y_batch\n",
    "            }\n",
    "        )\n",
    "\n",
    "    if e % 5 == 0:\n",
    "        summary = sess.run(\n",
    "            merged,\n",
    "            feed_dict={\n",
    "                word_ids: X_val,\n",
    "                y: y_val\n",
    "            }\n",
    "        )\n",
    "    if e % 1 == 0:\n",
    "        train_acc = []\n",
    "        for X_batch, y_batch in zip(X_train_batches, y_train_batches):\n",
    "            train_acc.append(accuracy.eval(\n",
    "                feed_dict={word_ids: X_batch, y: y_batch}\n",
    "            ))\n",
    "        avg_tarin_acc = np.mean(train_acc)\n",
    "        val_acc = accuracy.eval(feed_dict={word_ids: X_val, y: y_val})\n",
    "        print(\n",
    "            f\"Epochs[{e}]: train batch avg accuracy={avg_tarin_acc}, val accuracy={val_acc}\")\n",
    "    writer.add_summary(summary, e)\n",
    "    writer.close()\n",
    "f = lambda src: pred_idx.eval(feed_dict={word_ids: src})\n",
    "train_pred = f(X_train)\n",
    "test_pred = f(X_test)\n",
    "val_pred = f(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence2ints(sentence):\n",
    "    tokens = sentence.split()\n",
    "    ids = [word_to_index[word] for word in tokens]\n",
    "    ids = pad_sequences([ids], maxlen=max_seq_length, padding=\"post\", truncating=\"post\")\n",
    "    return np.array(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = \"What a nice day What a nice day What a nice day What a nice day What a nice day \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 40)\n",
      "[[190   6 490 164 190   6 490 164 190   6 490 164 190   6 490 164 190   6\n",
      "  490 164   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0]]\n"
     ]
    }
   ],
   "source": [
    "encoded = sentence2ints(s)\n",
    "print(encoded.shape)\n",
    "print(encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neutral\n"
     ]
    }
   ],
   "source": [
    "idx = pred_idx.eval(feed_dict={word_ids: encoded})\n",
    "print(SENTI_LST[int(idx)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.213375"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(np.argmax(y_test, axis=1) == test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@doctorsound I am 28 and I still haven't been to a club. Lots of bars, though. I don't think I'm missing much\n",
      "empty\n"
     ]
    }
   ],
   "source": [
    "n = 28888\n",
    "print(df[\"content\"][n])\n",
    "print(df[\"sentiment\"][n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.130225"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(df[\"sentiment\"] == \"happiness\") / len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
