{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import datetime\n",
    "from sklearn.model_selection import train_test_split\n",
    "import _pickle as pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def progbar(curr, total, full_progbar):\n",
    "    \"\"\"\n",
    "    Progress bar used in training process.\n",
    "    Reference: https://geekyisawesome.blogspot.com/2016/07/python-console-progress-bar-using-b-and.html\n",
    "    \"\"\"\n",
    "    frac = curr/total\n",
    "    filled_progbar = round(frac*full_progbar)\n",
    "#     print('\\r', '#'*filled_progbar + '-'*(\n",
    "#         full_progbar-filled_progbar), '[{:>7.2%}]'.format(frac), end='')\n",
    "    print('\\r', '#'*filled_progbar + '-'*(\n",
    "        full_progbar-filled_progbar), f\"[{curr}/{total}, {frac:>7.2%}]\\n\", end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>author</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1956967341</td>\n",
       "      <td>empty</td>\n",
       "      <td>xoshayzers</td>\n",
       "      <td>@tiffanylue i know  i was listenin to bad habi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1956967666</td>\n",
       "      <td>sadness</td>\n",
       "      <td>wannamama</td>\n",
       "      <td>Layin n bed with a headache  ughhhh...waitin o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1956967696</td>\n",
       "      <td>sadness</td>\n",
       "      <td>coolfunky</td>\n",
       "      <td>Funeral ceremony...gloomy friday...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1956967789</td>\n",
       "      <td>enthusiasm</td>\n",
       "      <td>czareaquino</td>\n",
       "      <td>wants to hang out with friends SOON!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1956968416</td>\n",
       "      <td>neutral</td>\n",
       "      <td>xkilljoyx</td>\n",
       "      <td>@dannycastillo We want to trade with someone w...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     tweet_id   sentiment       author  \\\n",
       "0  1956967341       empty   xoshayzers   \n",
       "1  1956967666     sadness    wannamama   \n",
       "2  1956967696     sadness    coolfunky   \n",
       "3  1956967789  enthusiasm  czareaquino   \n",
       "4  1956968416     neutral    xkilljoyx   \n",
       "\n",
       "                                             content  \n",
       "0  @tiffanylue i know  i was listenin to bad habi...  \n",
       "1  Layin n bed with a headache  ughhhh...waitin o...  \n",
       "2                Funeral ceremony...gloomy friday...  \n",
       "3               wants to hang out with friends SOON!  \n",
       "4  @dannycastillo We want to trade with someone w...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"./text_emotion.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_dimensions = 300\n",
    "\n",
    "batch_size = 24\n",
    "lstm_units = 256\n",
    "num_classes = 13\n",
    "iterations = 100\n",
    "max_seq_length = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Re-read embedding?[Y/N]Y\n",
      " ##-------------------------------------- [108288/2196017,   4.93%]------------------------------------- [486/2196017,   0.02%][3954/2196017,   0.18%][4389/2196017,   0.20%] [4801/2196017,   0.22%]---------------------------------------- [5011/2196017,   0.23%][6676/2196017,   0.30%] [7483/2196017,   0.34%][8806/2196017,   0.40%][9210/2196017,   0.42%][9630/2196017,   0.44%]---------------------------------------- [10056/2196017,   0.46%][10464/2196017,   0.48%]---------------------------------------- [11315/2196017,   0.52%]---------------------------------------- [12148/2196017,   0.55%] [12599/2196017,   0.57%][15940/2196017,   0.73%][17292/2196017,   0.79%][19885/2196017,   0.91%][22417/2196017,   1.02%][23655/2196017,   1.08%][24487/2196017,   1.12%][24916/2196017,   1.13%][25252/2196017,   1.15%][25488/2196017,   1.16%][27267/2196017,   1.24%][28116/2196017,   1.28%][28973/2196017,   1.32%][29786/2196017,   1.36%]#--------------------------------------- [31907/2196017,   1.45%]#--------------------------------------- [34528/2196017,   1.57%][34952/2196017,   1.59%][35383/2196017,   1.61%][35805/2196017,   1.63%]#--------------------------------------- [36238/2196017,   1.65%][36659/2196017,   1.67%][37892/2196017,   1.73%][38799/2196017,   1.77%] [39637/2196017,   1.80%][40537/2196017,   1.85%]#--------------------------------------- [40970/2196017,   1.87%]#--------------------------------------- [44859/2196017,   2.04%][45160/2196017,   2.06%][45470/2196017,   2.07%]#--------------------------------------- [45772/2196017,   2.08%]#--------------------------------------- [46047/2196017,   2.10%][46286/2196017,   2.11%][46560/2196017,   2.12%] [46967/2196017,   2.14%][47413/2196017,   2.16%][47835/2196017,   2.18%]#--------------------------------------- [49130/2196017,   2.24%][50736/2196017,   2.31%]#--------------------------------------- [51632/2196017,   2.35%][52502/2196017,   2.39%][53416/2196017,   2.43%][53841/2196017,   2.45%][55129/2196017,   2.51%]#--------------------------------------- [55421/2196017,   2.52%][57565/2196017,   2.62%][58395/2196017,   2.66%][58761/2196017,   2.68%][59146/2196017,   2.69%][60474/2196017,   2.75%][61279/2196017,   2.79%][62573/2196017,   2.85%][63814/2196017,   2.91%][64233/2196017,   2.92%][64639/2196017,   2.94%][65065/2196017,   2.96%] [65489/2196017,   2.98%]#--------------------------------------- [65899/2196017,   3.00%][66289/2196017,   3.02%][69354/2196017,   3.16%][70232/2196017,   3.20%]#--------------------------------------- [71859/2196017,   3.27%][72691/2196017,   3.31%][73596/2196017,   3.35%][73985/2196017,   3.37%][74424/2196017,   3.39%][74826/2196017,   3.41%][76059/2196017,   3.46%][77667/2196017,   3.54%]#--------------------------------------- [78058/2196017,   3.55%][78508/2196017,   3.58%][79389/2196017,   3.62%][79818/2196017,   3.63%][81025/2196017,   3.69%][81829/2196017,   3.73%]##-------------------------------------- [82731/2196017,   3.77%][83154/2196017,   3.79%][83593/2196017,   3.81%][84873/2196017,   3.86%][85280/2196017,   3.88%][85714/2196017,   3.90%][86131/2196017,   3.92%][87445/2196017,   3.98%][87796/2196017,   4.00%][89095/2196017,   4.06%][89498/2196017,   4.08%]##-------------------------------------- [90343/2196017,   4.11%]##-------------------------------------- [91182/2196017,   4.15%][93294/2196017,   4.25%][94597/2196017,   4.31%]##-------------------------------------- [95448/2196017,   4.35%][96309/2196017,   4.39%][96732/2196017,   4.40%][100123/2196017,   4.56%]##-------------------------------------- [103079/2196017,   4.69%]##-------------------------------------- [103503/2196017,   4.71%]##-------------------------------------- [104371/2196017,   4.75%] [105630/2196017,   4.81%] [107993/2196017,   4.92%]"
     ]
    }
   ],
   "source": [
    "if bool(input(\"Re-read embedding?[Y/N]>>> \").upper() == \"Y\"):\n",
    "    with open('/home/ec2-user/data/glove.840B.300d.txt') as f:\n",
    "        content = f.readlines()\n",
    "    total_dict = {}\n",
    "    for i in range(len(content)):\n",
    "        progbar(i, len(content), 40)\n",
    "        this = content[i].split()\n",
    "        try:\n",
    "            total_dict[this[0]] = np.array(this[1:]).astype(np.float32)\n",
    "        except:\n",
    "            for i in range(len(this[1:])):\n",
    "                try:\n",
    "                    np.array(this[1:][i]).astype(np.float32)\n",
    "                except:\n",
    "                    this[i+1] = '0.0'\n",
    "            total_dict[this[0]] = np.array(this[1:]).astype(np.float32)\n",
    "\n",
    "    with open('dict.pkl', 'wb') as f:\n",
    "        pickle.dump(total_dict, f)\n",
    "else:\n",
    "    with open('./dict.pkl', 'rb') as f:\n",
    "        total_dict = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "senti_lst = list(set(df[\"sentiment\"]))\n",
    "print(senti_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_raw = []\n",
    "y_raw = []\n",
    "for i, (senti, item) in enumerate(zip(df[\"sentiment\"], df[\"content\"])):\n",
    "    progbar(i, len(df), 50)\n",
    "    sentence = item.split()\n",
    "    vec_lst = list()\n",
    "    for word in sentence:\n",
    "        try:\n",
    "            vec_lst.append(total_dict[word][:num_dimensions])\n",
    "        except KeyError:\n",
    "#             vec_lst.append(np.zeros([num_dimensions]))\n",
    "            vec_lst.append(total_dict[\"something\"])\n",
    "    while len(vec_lst) < max_seq_length:\n",
    "        vec_lst.append(np.zeros([num_dimensions])\n",
    "        )\n",
    "    vec_ary = np.stack(vec_lst)\n",
    "    X_raw.append(vec_ary)\n",
    "    \n",
    "    # ==== Process y ====\n",
    "    y_idx = sentis.index(senti)\n",
    "    label = np.zeros([num_classes])\n",
    "    label[y_idx] = 1\n",
    "    assert sum(label) == 1\n",
    "    y_raw.append(label)\n",
    "X_raw = np.array(X_raw)\n",
    "y_raw = np.array(y_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"X shape: {X_raw.shape}\")\n",
    "print(f\"y shape: {y_raw.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (i, truth) in zip(range(y_raw.shape[0]), df[\"sentiment\"]):\n",
    "    idx = np.squeeze(np.where(y_ary[i, :] == 1))\n",
    "    assert senti_lst[idx] == truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, X_test,\n",
    " y_train, y_test) = train_test_split(\n",
    "    X_raw, y_raw,\n",
    "    test_size=0.2,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "(X_train, X_val,\n",
    " y_train, y_val) = train_test_split(\n",
    "    X_train, y_train,\n",
    "    test_size=0.2,\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Training and testing set generated,\\\n",
    "\\nX_train shape: {X_train.shape}\\\n",
    "\\ny_train shape: {y_train.shape}\\\n",
    "\\nX_test shape: {X_test.shape}\\\n",
    "\\ny_test shape: {y_test.shape}\\\n",
    "\\nX_validation shape: {X_val.shape}\\\n",
    "\\ny_validation shape: {y_val.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_ary.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentis = list(set(df[\"sentiment\"]))\n",
    "print(sentis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentis.index(df[\"sentiment\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost = 0\n",
    "for i in range(len(df.content[0].split())):\n",
    "    try:\n",
    "        cost += np.linalg.norm(total_dict[df.content[0].split()[i]][:300] - X_raw[0][i])\n",
    "    except:\n",
    "        cost += np.linalg.norm(total_dict[\"something\"][:300] - X_raw[0][i])\n",
    "print(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "with tf.name_scope(\"DATA_IO\"):\n",
    "    X = tf.placeholder(\n",
    "        tf.float32,\n",
    "        [None, max_seq_length, num_dimensions]\n",
    "    )\n",
    "    y = tf.placeholder(\n",
    "        tf.float32,\n",
    "        [None, num_classes]\n",
    "    )\n",
    "    \n",
    "with tf.name_scope(\"RNN\"):\n",
    "    lstm_cell = tf.contrib.rnn.LSTMCell(\n",
    "        num_units=lstm_units\n",
    "    )\n",
    "    lstm_cell = tf.contrib.rnn.DropoutWrapper(\n",
    "        cell=lstm_cell,\n",
    "        output_keep_prob=0.75\n",
    "    )\n",
    "    outputs, state = tf.nn.dynamic_rnn(\n",
    "        lstm_cell, \n",
    "        X, \n",
    "        dtype=tf.float32\n",
    "    )\n",
    "\n",
    "with tf.name_scope(\"OUTPUT\"):\n",
    "    weight = tf.Variable(\n",
    "        tf.truncated_normal(\n",
    "            [lstm_units, num_classes]\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    bias = tf.Variable(\n",
    "        tf.constant(\n",
    "            0.1, shape=[num_classes]\n",
    "        )\n",
    "    )\n",
    "    \n",
    "#     value = tf.transpose(value, [1, 0, 2])\n",
    "    \n",
    "#     last = tf.gather(value, int(value.get_shape()[0]) - 1)\n",
    "    last = outputs[:, -1, :]\n",
    "    pred = tf.matmul(last, weight) + bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"METRICS\"):\n",
    "    correct_pred = tf.equal(\n",
    "        tf.argmax(pred, axis=1),\n",
    "        tf.argmax(y, axis=1)\n",
    "    )\n",
    "\n",
    "    accuracy = tf.reduce_mean(\n",
    "        tf.cast(correct_pred, tf.float32)\n",
    "    )\n",
    "\n",
    "with tf.name_scope(\"LOSSES\"):\n",
    "    loss = tf.reduce_mean(\n",
    "        tf.nn.softmax_cross_entropy_with_logits(\n",
    "            logits=pred,\n",
    "            labels=y\n",
    "        )\n",
    "    )\n",
    "    optimizer = tf.train.AdamOptimizer().minimize(loss)\n",
    "\n",
    "tf.summary.scalar(\"Loss\", loss)\n",
    "tf.summary.scalar(\"Accuracy\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "merged = tf.summary.merge_all()\n",
    "logdir = \"./tensorboard/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\") + \"/\"\n",
    "tf.summary.FileWriter(logdir, sess.graph)\n",
    "\n",
    "for e in range(iterations):\n",
    "    sess.run(\n",
    "        optimizer,\n",
    "        feed_dict={\n",
    "            X: X_train,\n",
    "            y: y_train\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    if e % 5 == 0:\n",
    "        summary = sess.run(\n",
    "            merged,\n",
    "            feed_dict={\n",
    "                X: X_val,\n",
    "                y: y_val\n",
    "            }\n",
    "        )\n",
    "    writer.add_summary(summary, e)\n",
    "    writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
