{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_dimensions = 300\n",
    "\n",
    "batch_size = 24\n",
    "lstm_units = 64\n",
    "num_classes = 13\n",
    "iterations = 100\n",
    "max_seq_length = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'word_vector' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-e56a76a31380>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m     ))\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m     \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding_lookup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword_vector\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"RNN\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'word_vector' is not defined"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "\n",
    "with tf.name_scope(\"DATA_IO\"):\n",
    "    input_data = tf.placeholder(\n",
    "        tf.int32,\n",
    "        [batch_size, max_seq_length]\n",
    "    )\n",
    "    labels = tf.placeholder(\n",
    "        tf.float32,\n",
    "        [batch_size, num_classes]\n",
    "    )\n",
    "\n",
    "with tf.name_scope(\"DATA_PROC\"):\n",
    "    data = tf.Variable(tf.zeros(\n",
    "        [batch_size, max_seq_length, num_dimensions]\n",
    "    ))\n",
    "\n",
    "    tf.nn.embedding_lookup(word_vector, input_data)\n",
    "\n",
    "with tf.name_scope(\"RNN\"):\n",
    "    lstm_cell = tf.rnn.BasicLSTMCell(lstm_units)\n",
    "    lstm_cell = tf.contrib.rnn.DropoutWrapper(\n",
    "        cell=lstm_cell,\n",
    "        output_keep_prob=0.75\n",
    "    )\n",
    "    value, _ = tf.nn.dynamic_rnn(lstm_cell, data, dtype=tf.float32)\n",
    "\n",
    "with tf.name_scope(\"OUTPUT\"):\n",
    "    weight = tf.Variable(\n",
    "        tf.truncated_normal(\n",
    "            [lstm_units, num_classes]\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    bias = tf.Variable(\n",
    "        tf.constant(\n",
    "            0.1, shape=[num_classes]\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    value = tf.transpose(value, [1, 0, 2])\n",
    "    \n",
    "    last = tf.gather(value, int(value.get_shape()[0]) - 1)\n",
    "    prediction = tf.matmul(last, weight) + bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'prediction' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-0e3d8dcb4cb1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m correct_pred = tf.equal(\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m )\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'prediction' is not defined"
     ]
    }
   ],
   "source": [
    "with tf.name_scope(\"METRICS\"):\n",
    "    correct_pred = tf.equal(\n",
    "        tf.argmax(prediction, axis=1),\n",
    "        tf.argmax(labels, axis=1)\n",
    "    )\n",
    "\n",
    "    accuracy = tf.reduce_mean(\n",
    "        tf.cast(correct_pred, tf.float32)\n",
    "    )\n",
    "\n",
    "with tf.name_scope(\"LOSSES\"):\n",
    "    loss = tf.reduce_mean(\n",
    "        tf.nn.softmax_cross_entropy_with_logits(\n",
    "            logits=prediction,\n",
    "            labels=labels\n",
    "        )\n",
    "    )\n",
    "    optimizer = tf.train.AdamOptimizer().minimize(loss)\n",
    "\n",
    "tf.summary.scalar(\"Loss\", loss)\n",
    "tf.summary.scalar(\"Accuracy\", aacuracy)\n",
    "\n",
    "merged = tf.summary.merge_all()\n",
    "logdir = \"./tensorflow/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\") + \"/\"\n",
    "tf.summary.FileWriter(logdir, sess.graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n",
    "for e in range(iterations):\n",
    "    next_batch, next_batch_labels = get_train_batch()\n",
    "    sess.run(\n",
    "        optimizer,\n",
    "        feed_dict={\n",
    "            input_data: next_batch,\n",
    "            labels: next_batch_labels\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    if e % 5 == 0:\n",
    "        summary = sess.run(\n",
    "            merged,\n",
    "            feed_dict={\n",
    "                input_data: next_batch,\n",
    "                labels: next_batch_labels\n",
    "            }\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
